import pandas as pd

NOTE:DONT USE df.loc["column name"] its stupid and doesnt work 



loading in files that have no headers-------------------------------------
df=pd.read_csv("init1d_t0100.dat", delimiter=" ",header=None) #do this otherwise the first line of the file is ignored


dataframe (is referred to in python as df): like the table of data. consists of index(like rows) with index label 
(can be row number), columns with column label,and values (data)

row or column are often refered to as an axis

subset selection (also called indexing): when you select particular rows and/or columns within the dataframe

integer location: the number assigned to an partiular row or column. starts from 0, goes to n-1

indexers: commands that help you index/subset select. they are [], .iloc, .loc
BUT df[] is also called the indexing operator

COMMAND pd.read_csv('sample_data.csv', index_col=0): reads in a comman seperated data set called sample_data.csv, and 
focuses on the column n=0

you can convert files to .csv by using the following command:

import pandas as pd
df = pd.read_csv("Demo.txt",delimiter='<input whatever is used to seperate the data values from one another>')
df.to_csv('Demo1.csv')

viewing just the top three rows of the data : print(df.head(3))

to look for certain bits of data: 
import numpy as np
import pandas as pd

df=pd.read_csv("dinner.csv")

is_t_4_05= df['label_3']==4.05 #defines t_4_05 as column 3 where the row elements are equal to 4.05

df_4_05=df[is_t_4_05] #sets the df_4_05 to equal to what we defined above

this will allow you to look at only the data where in column 3, the row elements have values 4.05


slicing dataframes-------------------------
lets say density is some column of a larger data file init3d_t0100.dat and we want rows 0-10
density=df.iloc[:,[4]]
density_slice=density[0:10]

setting column names---------------------
df.columns=['l1', 'l2', 'l3', 'l4', 'l5', 'l6', 'l7', 'l8', 'l9', 'l10', 'l11', 'l12', 'l13', 'l14', 'l15', 'l16', 'l17', 'l18', 'l19', 'l20', 'l21', 'l22']

removing columns-------------------------
del df['column name']


---------------------------------------dimensional reduction-------------------------------------
from sklearn.datasets import make_classification
make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)
 #this command makes up a random data set with seed 7, 10 redundant columns, 10 useful columns, 20 columns (or dimensions) in total, and 1000 data points
 
 making 2D array with 2 one dimensional arrays----------------------------------
 data=np.vstack((<array1>, <array2>)).T
 
making n dimensional array based on n arrays------------------------
data_comp=np.stack((he,c,ne,mg,si,s,ar,ca,ti,cr,fe,ni), axis=0, out=None).T


DELETING COLUMNS WITH NUMPY===================================================

numpy.delete(arr, obj, axis=None)
arr is the array name 
obj is the row or column number 
axis=0,1 #0 if you want to delete a row, 1 if you want to delete a column
